{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/WITTER-JHU-APL/josh-understanding-data/blob/main/Josh_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JndnmDMp66FL"
   },
   "source": [
    "#### Copyright 2017 Google LLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "id": "hMqWDc_m6rUC"
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f3CKqFUqL2-"
   },
   "source": [
    "#Lab 1: Loading and Understanding Your Data\n",
    "\n",
    "\n",
    "**Learning Objectives:**\n",
    "* Learn the basics of reading data with Pandas\n",
    "* Learn the basics of data cleaning and handling missing data using Pandas\n",
    "* Learning how to visualize data with a scatter plot\n",
    "* Use Numpy to generate the line minimizing squared loss\n",
    "* Explore visually the difference in the model when replacing missing items by 0s versus the mean value for that feature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if3EBefJeqKq"
   },
   "source": [
    "## Data Set\n",
    "This lab will use a data set from 1985 Ward's Automotive Yearbook that is part of the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets) under [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile).  You can find a description of the data at [https://archive.ics.uci.edu/ml/datasets/automobile](https://archive.ics.uci.edu/ml/datasets/automobile). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h94BDSHgeKev"
   },
   "source": [
    "## Imports\n",
    "In this first cell, we'll import some libraries, including Pandas that will be used later to read and load the data. Run this cell to execute the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6CspO1zVopXj",
    "outputId": "d9e8b815-1070-47a0-a2d3-0f2e296d2324"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d75f1c3d86fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlearn_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.contrib'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn import learn_io, estimator\n",
    "\n",
    "# TF2.0 Install:\n",
    "# Remove Python 3.9\n",
    "# Install Python 3.8\n",
    "# Remove all python references to 3.9\n",
    "# brew doctor\n",
    "# delete other config files found by brew\n",
    "# brew cleanup\n",
    "# hope & pray you remembered everything correctly\n",
    "\n",
    "import math\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# This line incrasing the amount of logging when there is an error.  You can\n",
    "# remove it if you want less logging\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "print(\"Done with the imports.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gH_CmiFUfECG"
   },
   "source": [
    "## Pandas -- Python Data Analysis Library\n",
    "\n",
    "We are using a package called [Pandas](http://pandas.pydata.org/) for reading in our data, exploring our data and doing some basic processing.  First \n",
    "we set up some options to control how items are displayed and the maximum number of rows to show when displaying a table.  Feel free to change this setup to whatever you'd like.\n",
    "\n",
    "As illustrated below, in colab you can define code cells that do not generate any output. In fact, the first cell would also have been that way except for the `print` statement at the end added just to help illustrate this aspect of colab. If at any point you are not sure if a cell is successfully running, you can add a print statement, but that should not be necessary since you can visually see when the cell is done running when the arrow is showing again. Also note that when you select the next cell the number showing the execution order of the cell appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkipsYVxfDv4"
   },
   "outputs": [],
   "source": [
    "# Set the output display to have one digit for decimal places, for display\n",
    "# readability only and limit it to printing 15 rows.\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.max_rows = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F9TLXouIfYQI"
   },
   "source": [
    "### Loading the Data Set with Pandas\n",
    "The car data set we will be using in this lab is provided as a comma separated file without a header row.  In order, for each column to have a meaningful header name we must provide it.  We get the information about the columns from [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wXuaBqVufYF4",
    "outputId": "b79bef62-4bdd-4331-c0f7-3278cd5bcabc"
   },
   "outputs": [],
   "source": [
    "# Provide the names for the columns since the CSV file with the data does\n",
    "# not have a header row.\n",
    "cols = ['symboling', 'losses', 'make', 'fuel-type', 'aspiration', 'num-doors',\n",
    "        'body-style', 'drive-wheels', 'engine-location', 'wheel-base',\n",
    "        'length', 'width', 'height', 'weight', 'engine-type', 'num-cylinders',\n",
    "        'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio',\n",
    "        'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "\n",
    "\n",
    "# Load in the data from a CSV file that is comma seperated.\n",
    "car_data = pd.read_csv('https://storage.googleapis.com/ml_universities/cars_dataset/cars_data.csv',\n",
    "                        sep=',', names=cols, header=None, encoding='latin-1')\n",
    "\n",
    "print(\"Data set loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzzlSs3PtTmt"
   },
   "source": [
    "### Examine the Data\n",
    "\n",
    "It's a good idea to get to know your data a little bit before you work with it. Let's look at the header row and the first 10 rows of data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "id": "tVmE-kNotzWG",
    "outputId": "eaaaecd5-accc-4761-ceb4-6d438feb0bcc"
   },
   "outputs": [],
   "source": [
    "car_data[1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cih-K3tetkgb"
   },
   "source": [
    "### Look at Some Basic Statistics About the Data\n",
    "We'll print out a quick summary of a few useful statistics on each column. This will include things like mean, standard deviation, max, min, and various quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "gzb10yoVrydW",
    "outputId": "c98fcec6-6489-45c8-e14d-f1970047782b"
   },
   "outputs": [],
   "source": [
    "car_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPUHcV0vuOAW"
   },
   "source": [
    "### Handling Missing Data Entries\n",
    "Why are some columns such as the price and losses not showing in the summary column?  If we look at the data more carefuly, we'll see that a \"?\" was used in this data set to indicate that a value is unknown.\n",
    "\n",
    "Pandas provices a method [to_numeric](http://pandas.pydata.org/pandas-docs/version/0.18.1/generated/pandas.to_numeric.html) that converts a column to be numeric. There are three options about how to handle errors (entries that are not numeric) of which 'coerce' is what we want to use in this situation, since it converts those entries to pandas representation `NaN` for \"not a number\".\n",
    "\n",
    "Notice now when you use `describe` to see the statistics for the entries that are a number, the count indicates how many entries had a number (not `NaN`) for that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "WJg129wyugzF",
    "outputId": "21515192-d75f-42b9-ee03-d62d993be3f2"
   },
   "outputs": [],
   "source": [
    "car_data['price'] = pd.to_numeric(car_data['price'], errors='coerce')\n",
    "car_data['horsepower'] = pd.to_numeric(car_data['horsepower'], errors='coerce')\n",
    "car_data['peak-rpm'] = pd.to_numeric(car_data['peak-rpm'], errors='coerce')\n",
    "car_data['city-mpg'] = pd.to_numeric(car_data['city-mpg'], errors='coerce')\n",
    "car_data['highway-mpg'] = pd.to_numeric(car_data['highway-mpg'], errors='coerce')\n",
    "car_data['losses'] = pd.to_numeric(car_data['losses'], errors='coerce')\n",
    "car_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3pU9zynBiU0x"
   },
   "source": [
    "### Replacing NAN by zero\n",
    "When training a linear model using features that is numerical, we **cannot have `NaN` (doing so would cause overflow when training)**. Here we replace `NaN` (which corresponding to where we had missing entries) by 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "Fsg8khAgiUm9",
    "outputId": "08d9df1c-510c-4f0d-d8dd-6aa176df8d65"
   },
   "outputs": [],
   "source": [
    "# Replace nan by the mean storing the solution in the same table (`inplace')\n",
    "car_data.fillna(0, inplace=True)\n",
    "car_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ct-amQLex0oD"
   },
   "source": [
    "### Using a Scatter Plot to Visualize the Data\n",
    "\n",
    "We will begin by trying to predict the price using the horsepower.  Because we just have a single feature we can visualize the raw data using a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "yq5AhcxEx3TC",
    "outputId": "1afb0e02-98ef-463a-aa54-26bdcf1d7e98"
   },
   "outputs": [],
   "source": [
    "INPUT_FEATURE = \"horsepower\"\n",
    "LABEL = \"price\"\n",
    "\n",
    "plt.ylabel(LABEL)\n",
    "plt.xlabel(INPUT_FEATURE)\n",
    "plt.scatter(car_data[INPUT_FEATURE], car_data[LABEL], c='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgjPhuWBKC2z"
   },
   "source": [
    "###Using numpy polyfit to find the line that minimizes RMSE\n",
    "For the task of finding a line that minimizes the squared error with respect to a set of points, using SGD is not the most efficient method but it will be useful in that it can be applied to much more complex problems.  As a tool to help see what the optimal solution looks like we wil use `polyfit` to compute the optimal solution and then add that to our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqGOYfA2L6LX",
    "outputId": "3009282b-5d68-4a38-a220-cb0c75eb3ff1"
   },
   "outputs": [],
   "source": [
    "x = car_data[INPUT_FEATURE]\n",
    "y = car_data[LABEL]\n",
    "opt = np.polyfit(x, y, 1)\n",
    "y_pred = opt[0] * x + opt[1]\n",
    "opt_rmse = math.sqrt(metrics.mean_squared_error(y_pred, y))\n",
    "slope = opt[0]\n",
    "bias = opt[1]\n",
    "print(\"Optimal RMSE =\", opt_rmse, \"for solution\", opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7qT33YbG3Jf"
   },
   "source": [
    "### Showing A Linear Regression Model in a Scatter Plot\n",
    "To help provide intuition to what is being learned by a linear regression model and as a way to visualzize the quality, we provide a method to create the scatter plot of a single input feature with respect to the label feature.  In addition, a set of lines (from different linear regression models) as provided as a list of slopes, biases and model_names for the legend can be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTzgIq_hZL0m"
   },
   "outputs": [],
   "source": [
    "def make_scatter_plot(dataframe, input_feature, target,\n",
    "                      slopes=[], biases=[], model_names=[]):\n",
    "  \"\"\" Creates a scatter plot of input_feature vs target along with the models.\n",
    "  \n",
    "  Args:\n",
    "    dataframe: the dataframe to visualize\n",
    "    input_feature: the input feature to be used for the x-axis\n",
    "    target: the target to be used for the y-axis\n",
    "    slopes: list of model weight (slope) \n",
    "    bias: list of model bias (same size as slopes)\n",
    "    model_names: list of model_names to use for legend (same size as slopes)\n",
    "  \"\"\"      \n",
    "  # Define some colors to use that go from blue towards red\n",
    "  colors = [cm.coolwarm(x) for x in np.linspace(0, 1, len(slopes))]\n",
    "  \n",
    "  # Generate the Scatter plot\n",
    "  x = dataframe[input_feature]\n",
    "  y = dataframe[target]\n",
    "  plt.ylabel(target)\n",
    "  plt.xlabel(input_feature)\n",
    "  plt.scatter(x, y, color='black', label=\"\")\n",
    "\n",
    "  # Add the lines corresponding to the provided models\n",
    "  for i in range (0, len(slopes)):\n",
    "    y_0 = slopes[i] * x.min() + biases[i]\n",
    "    y_1 = slopes[i] * x.max() + biases[i]\n",
    "    plt.plot([x.min(), x.max()], [y_0, y_1],\n",
    "             label=model_names[i], color=colors[i])\n",
    "  if (len(model_names) > 0):\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "aVlGG6cRINfP",
    "outputId": "e79b45fe-b466-4ee4-854e-83c6e3b97ed6"
   },
   "outputs": [],
   "source": [
    "make_scatter_plot(car_data,INPUT_FEATURE, LABEL,\n",
    "                  [slope], [bias], [\"initial model\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPBoFxzRSHol"
   },
   "source": [
    "## Task 1: Create a scatter plot for new features (1 Point)\n",
    "\n",
    "Create a scatter plot with price as the input feature and losses as the label where the line optimizing the squared loss is shown.  We've gotten you started.  You just need to copy the appropriate lines from above.  **Save the slope and bias from this line to be used in a later task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "id": "P64o23hPSZ5N",
    "outputId": "c86a5121-e66f-4018-a169-a41231e230f8"
   },
   "outputs": [],
   "source": [
    "INPUT_FEATURE = \"price\"\n",
    "LABEL = \"losses\"\n",
    "\n",
    "# Fill in the rest of this block.\n",
    "x = car_data[INPUT_FEATURE]\n",
    "y = car_data[LABEL]\n",
    "opt = np.polyfit(x, y, 1)\n",
    "y_pred = opt[0] * x + opt[1]\n",
    "opt_rmse = math.sqrt(metrics.mean_squared_error(y_pred, y))\n",
    "slope = opt[0]\n",
    "bias = opt[1]\n",
    "print(\"Optimal RMSE =\", opt_rmse, \"for solution\", opt)\n",
    "print(opt[0])\n",
    "print(bias)\n",
    "\n",
    "make_scatter_plot(car_data,INPUT_FEATURE, LABEL,\n",
    "                  [slope], [bias], [\"initial model\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYamoYZmLENA"
   },
   "source": [
    "## Task 2: Explain what you see (1 point)\n",
    "\n",
    "Explain why we are seeing so many points along the line `y=0`.\n",
    "\n",
    "----------------------------\n",
    "\n",
    "Due to so many of the cars losses being NaN or 0 they all sit along the y=0 line because losses are lined along the y axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZLePi8V8za1"
   },
   "source": [
    "##Task 3: Options to handle missing data (3 Points)\n",
    "\n",
    "In this task you will explore alternate ways to handle missing data. When training a linear model using features that are numerical, we **cannot have `NaN` (doing so would cause overflow when training)**. One option is to just discard any rows with any missing entries but often this would not leave enough data.  Here we explore ways to handle the missing data without just discarding it.\n",
    "\n",
    "Note that when you get a column of a dataframe (e.g. car_data[\"price']), you get a `Series`.  Read [http://pandas.pydata.org/pandas-docs/version/0.18.1/api.html#computations-descriptive-stats](http://pandas.pydata.org/pandas-docs/version/0.18.1/api.html#computations-descriptive-stats) and think about if you see any statistics for a column that might make a better choice than 0 for filling in the missing entries.What do you think would work best?\n",
    "\n",
    "Modify the code to use the function you selected to replace missings instead of just using 0 and both look at the scatter plot and the line minimizing RMSE both with the missings replaced by 0 and the missing entries replaced by the option you pick.  Feel free to show multiple options as a tool to help you explain your choice of which you think is best..  What option do you think is best and why?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83z_EMLGVoUp"
   },
   "outputs": [],
   "source": [
    "# Load in the data from a CSV file that is comma seperated.\n",
    "car_data_v2 = pd.read_csv('https://storage.googleapis.com/ml_universities/cars_dataset/cars_data.csv',\n",
    "                           sep=',', names=cols, header=None, encoding='latin-1')\n",
    "car_data_v2['price'] = pd.to_numeric(car_data_v2['price'], errors='coerce')\n",
    "car_data_v2['losses'] = pd.to_numeric(car_data_v2['losses'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQzTdE24VbB5"
   },
   "outputs": [],
   "source": [
    "# Fill in what you want to do with the nan here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "ExbogDLANDQr",
    "outputId": "22bb287b-3ed0-4e7a-8af5-9cd9b5edf050"
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot with the model from above (when NA replaced by 0) and at least one other option.\n",
    "INPUT_FEATURE = \"price\"\n",
    "LABEL = \"losses\"\n",
    "\n",
    "x = car_data_v2[INPUT_FEATURE]\n",
    "y = car_data_v2[LABEL]\n",
    "opt = np.polyfit(x, y, 1)\n",
    "y_pred = opt[0] * x + opt[1]\n",
    "opt_rmse = math.sqrt(metrics.mean_squared_error(y_pred, y))\n",
    "slope = opt[0]\n",
    "bias = opt[1]\n",
    "print(\"Optimal RMSE =\", opt_rmse, \"for solution\", opt)\n",
    "print(opt[0])\n",
    "print(bias)\n",
    "\n",
    "make_scatter_plot(car_data_v2,INPUT_FEATURE, LABEL,\n",
    "                  [slope], [bias], [\"initial model\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEXKjXMZRv-q"
   },
   "source": [
    "-----------------\n",
    "\n",
    "**Put your answer here to what option you think is best and why here**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JndnmDMp66FL"
   ],
   "include_colab_link": true,
   "name": "Copy of Copy_of_Lab_1_Loading_and_Understanding_Your_Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}